{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MRP-fAQedMTd"
   },
   "source": [
    "<h2> 3.6 Featurizing text data with tfidf weighted word-vectors </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-3IbomL8dMTi",
    "outputId": "3fa8eb7c-ddf2-4f98-edee-0c49db6502e8"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import time\n",
    "import warnings\n",
    "import numpy as np\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from sklearn.model_selection import train_test_split\n",
    "import sys\n",
    "import os \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "# exctract word2vec vectors\n",
    "# https://github.com/explosion/spaCy/issues/1721\n",
    "# http://landinghub.visualstudio.com/visual-cpp-build-tools\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "j5XNgVyLdMT7"
   },
   "outputs": [],
   "source": [
    "# avoid decoding problems\n",
    "df = pd.read_csv(\"train.csv\")[:100000]\n",
    " \n",
    "# encode questions to unicode\n",
    "# https://stackoverflow.com/a/6812069\n",
    "# ----------------- python 2 ---------------------\n",
    "# df['question1'] = df['question1'].apply(lambda x: unicode(str(x),\"utf-8\"))\n",
    "# df['question2'] = df['question2'].apply(lambda x: unicode(str(x),\"utf-8\"))\n",
    "# ----------------- python 3 ---------------------\n",
    "df['question1'] = df['question1'].apply(lambda x: str(x))\n",
    "df['question2'] = df['question2'].apply(lambda x: str(x))\n",
    "df[\"question\"] = df[\"question1\"].map(str) +\\\n",
    "                 df[\"question2\"].map(str)\n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.head(5)\n",
    "# Y = df['is_duplicate']\n",
    "# X = df\n",
    "# del X['is_duplicate']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# del df['is_duplicate']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting the data before vectorizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test, y_train, y_test = train_test_split(X, Y, stratify=Y, test_size=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TFIDF Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HbiMFpgRdMUJ",
    "outputId": "21c00698-7f2a-4ce4-e665-f7a2feaab6fa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_train_question_1_tfidf matrix  (283003, 74498)\n",
      "Shape of X_test_question_1_tfidf matrix (121287, 74498)\n"
     ]
    }
   ],
   "source": [
    "vectorizer_tfidf_question_1 = TfidfVectorizer()\n",
    "\n",
    "X_train_question_tfidf = vectorizer_tfidf_question_1.fit_transform(X_train['question'])\n",
    "X_test_question_tfidf = vectorizer_tfidf_question_1.transform(X_test['question'])\n",
    "print(\"Shape of X_train_question_1_tfidf matrix \",X_train_question_tfidf.shape)\n",
    "print(\"Shape of X_test_question_1_tfidf matrix\",X_test_question_tfidf.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['00', '000', '0000', '00000000', '0000000000']\n",
      "[ 9.41008158  6.86113257 12.86006913 12.86006913 12.86006913]\n"
     ]
    }
   ],
   "source": [
    "print(vectorizer_tfidf_question_1.get_feature_names()[:5])\n",
    "print(vectorizer_tfidf_question_1.idf_[:5])\n",
    "# type(X_train_question_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RU3HqJXwdMUj"
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "# merge texts\n",
    "questions = list(df['question1']) + list(df['question2'])\n",
    "\n",
    "tfidf = TfidfVectorizer(lowercase=False, )\n",
    "tfidf.fit_transform(questions)\n",
    "\n",
    "# dict key:word and value:tf-idf score\n",
    "word2tfidf = dict(zip(tfidf.get_feature_names(), tfidf.idf_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# word2tfidf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2JKI2yT4dMUv"
   },
   "source": [
    "- After we find TF-IDF scores, we convert each question to a weighted average of word2vec vectors by these scores.\n",
    "- here we use a pre-trained GLOVE model which comes free with \"Spacy\".  https://spacy.io/usage/vectors-similarity\n",
    "- It is trained on Wikipedia and therefore, it is stronger in terms of word semantics. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PFS6m8z5dMUz",
    "outputId": "3c4fb6fd-7f86-4955-8b8f-762b5969ecce"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100000/100000 [31:29<00:00, 52.91it/s]\n"
     ]
    }
   ],
   "source": [
    "# en_vectors_web_lg, which includes over 1 million unique vectors.\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "vecs1 = []\n",
    "# https://github.com/noamraph/tqdm\n",
    "# tqdm is used to print the progress bar\n",
    "for qu1 in tqdm(list(df['question1'])):\n",
    "    doc1 = nlp(qu1) \n",
    "    # 384 is the number of dimensions of vectors \n",
    "    mean_vec1 = np.zeros([len(doc1), len(doc1[0].vector)])\n",
    "    for word1 in doc1:\n",
    "        # word2vec\n",
    "        vec1 = word1.vector\n",
    "        # fetch df score\n",
    "        try:\n",
    "            idf = word2tfidf[str(word1)]\n",
    "        except:\n",
    "            idf = 0\n",
    "        # compute final vec\n",
    "        mean_vec1 += vec1 * idf\n",
    "    mean_vec1 = mean_vec1.mean(axis=0)\n",
    "    vecs1.append(mean_vec1)\n",
    "df['q1_feats_m'] = list(vecs1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [211.3274930715561, -144.7779631614685, -68.72...\n",
       "1    [142.841313123703, -114.03367304801941, -110.2...\n",
       "2    [82.5609240680933, -142.53362256288528, 0.7266...\n",
       "3    [-125.97513282299042, -59.42235966771841, -67....\n",
       "4    [299.5942276120186, -188.40130496025085, -21.2...\n",
       "Name: q1_feats_m, dtype: object"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['q1_feats_m'].head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "62GEF-RbdMVB",
    "outputId": "60a4f5f8-5582-4886-befd-2ab6ed99c753"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100000/100000 [35:42<00:00, 46.68it/s]\n"
     ]
    }
   ],
   "source": [
    "vecs2 = []\n",
    "for qu2 in tqdm(list(df['question2'])):\n",
    "    doc2 = nlp(qu2) \n",
    "    mean_vec2 = np.zeros([len(doc2), len(doc2[0].vector)])\n",
    "    for word2 in doc2:\n",
    "        # word2vec\n",
    "        vec2 = word2.vector\n",
    "        # fetch df score\n",
    "        try:\n",
    "            idf = word2tfidf[str(word2)]\n",
    "        except:\n",
    "            #print word\n",
    "            idf = 0\n",
    "        # compute final vec\n",
    "        mean_vec2 += vec2 * idf\n",
    "    mean_vec2 = mean_vec2.mean(axis=0)\n",
    "    vecs2.append(mean_vec2)\n",
    "df['q2_feats_m'] = list(vecs2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "a38GBlGWdMVQ"
   },
   "outputs": [],
   "source": [
    "#prepro_features_train.csv (Simple Preprocessing Feartures)\n",
    "#nlp_features_train.csv (NLP Features)\n",
    "if os.path.isfile('nlp_features_train.csv'):\n",
    "    dfnlp = pd.read_csv(\"nlp_features_train.csv\",encoding='latin-1')[0:100000]\n",
    "else:\n",
    "    print(\"download nlp_features_train.csv from drive or run previous notebook\")\n",
    "\n",
    "if os.path.isfile('df_fe_without_preprocessing_train.csv'):\n",
    "    dfppro = pd.read_csv(\"df_fe_without_preprocessing_train.csv\",encoding='latin-1')\n",
    "else:\n",
    "    print(\"download df_fe_without_preprocessing_train.csv from drive or run previous notebook\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "apdRa1kndMVb"
   },
   "outputs": [],
   "source": [
    "df1 = dfnlp.drop(['qid1','qid2','question1','question2'],axis=1)\n",
    "df2 = dfppro.drop(['qid1','qid2','question1','question2','is_duplicate'],axis=1)\n",
    "df3 = df.drop(['qid1','qid2','question1','question2','is_duplicate'],axis=1)\n",
    "df3_q1 = pd.DataFrame(df3.q1_feats_m.values.tolist(), index= df3.index)\n",
    "df3_q2 = pd.DataFrame(df3.q2_feats_m.values.tolist(), index= df3.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xzWAqGegdMVp",
    "outputId": "2f88eeda-244f-4bbb-a51c-a8680fe8fb92"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>is_duplicate</th>\n",
       "      <th>cwc_min</th>\n",
       "      <th>cwc_max</th>\n",
       "      <th>csc_min</th>\n",
       "      <th>csc_max</th>\n",
       "      <th>ctc_min</th>\n",
       "      <th>ctc_max</th>\n",
       "      <th>last_word_eq</th>\n",
       "      <th>first_word_eq</th>\n",
       "      <th>abs_len_diff</th>\n",
       "      <th>mean_len</th>\n",
       "      <th>token_set_ratio</th>\n",
       "      <th>token_sort_ratio</th>\n",
       "      <th>fuzz_ratio</th>\n",
       "      <th>fuzz_partial_ratio</th>\n",
       "      <th>longest_substr_ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.999980</td>\n",
       "      <td>0.833319</td>\n",
       "      <td>0.999983</td>\n",
       "      <td>0.999983</td>\n",
       "      <td>0.916659</td>\n",
       "      <td>0.785709</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>100</td>\n",
       "      <td>93</td>\n",
       "      <td>93</td>\n",
       "      <td>100</td>\n",
       "      <td>0.982759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.799984</td>\n",
       "      <td>0.399996</td>\n",
       "      <td>0.749981</td>\n",
       "      <td>0.599988</td>\n",
       "      <td>0.699993</td>\n",
       "      <td>0.466664</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>12.5</td>\n",
       "      <td>86</td>\n",
       "      <td>63</td>\n",
       "      <td>66</td>\n",
       "      <td>75</td>\n",
       "      <td>0.596154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.399992</td>\n",
       "      <td>0.333328</td>\n",
       "      <td>0.399992</td>\n",
       "      <td>0.249997</td>\n",
       "      <td>0.399996</td>\n",
       "      <td>0.285712</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>66</td>\n",
       "      <td>66</td>\n",
       "      <td>54</td>\n",
       "      <td>54</td>\n",
       "      <td>0.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>36</td>\n",
       "      <td>36</td>\n",
       "      <td>35</td>\n",
       "      <td>40</td>\n",
       "      <td>0.039216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.399992</td>\n",
       "      <td>0.199998</td>\n",
       "      <td>0.999950</td>\n",
       "      <td>0.666644</td>\n",
       "      <td>0.571420</td>\n",
       "      <td>0.307690</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>67</td>\n",
       "      <td>47</td>\n",
       "      <td>46</td>\n",
       "      <td>56</td>\n",
       "      <td>0.175000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  is_duplicate   cwc_min   cwc_max   csc_min   csc_max   ctc_min  \\\n",
       "0   0             0  0.999980  0.833319  0.999983  0.999983  0.916659   \n",
       "1   1             0  0.799984  0.399996  0.749981  0.599988  0.699993   \n",
       "2   2             0  0.399992  0.333328  0.399992  0.249997  0.399996   \n",
       "3   3             0  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "4   4             0  0.399992  0.199998  0.999950  0.666644  0.571420   \n",
       "\n",
       "    ctc_max  last_word_eq  first_word_eq  abs_len_diff  mean_len  \\\n",
       "0  0.785709           0.0            1.0           2.0      13.0   \n",
       "1  0.466664           0.0            1.0           5.0      12.5   \n",
       "2  0.285712           0.0            1.0           4.0      12.0   \n",
       "3  0.000000           0.0            0.0           2.0      12.0   \n",
       "4  0.307690           0.0            1.0           6.0      10.0   \n",
       "\n",
       "   token_set_ratio  token_sort_ratio  fuzz_ratio  fuzz_partial_ratio  \\\n",
       "0              100                93          93                 100   \n",
       "1               86                63          66                  75   \n",
       "2               66                66          54                  54   \n",
       "3               36                36          35                  40   \n",
       "4               67                47          46                  56   \n",
       "\n",
       "   longest_substr_ratio  \n",
       "0              0.982759  \n",
       "1              0.596154  \n",
       "2              0.166667  \n",
       "3              0.039216  \n",
       "4              0.175000  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dataframe of nlp features\n",
    "df1.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "N4DQnDtndMV4",
    "outputId": "2e288eed-e8fa-4ec3-a9b9-4e4daba52fc1"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>freq_qid1</th>\n",
       "      <th>freq_qid2</th>\n",
       "      <th>q1len</th>\n",
       "      <th>q2len</th>\n",
       "      <th>q1_n_words</th>\n",
       "      <th>q2_n_words</th>\n",
       "      <th>word_Common</th>\n",
       "      <th>word_Total</th>\n",
       "      <th>word_share</th>\n",
       "      <th>freq_q1+q2</th>\n",
       "      <th>freq_q1-q2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>66</td>\n",
       "      <td>57</td>\n",
       "      <td>14</td>\n",
       "      <td>12</td>\n",
       "      <td>10.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0.434783</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>51</td>\n",
       "      <td>88</td>\n",
       "      <td>8</td>\n",
       "      <td>13</td>\n",
       "      <td>4.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>73</td>\n",
       "      <td>59</td>\n",
       "      <td>14</td>\n",
       "      <td>10</td>\n",
       "      <td>4.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>65</td>\n",
       "      <td>11</td>\n",
       "      <td>9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>76</td>\n",
       "      <td>39</td>\n",
       "      <td>13</td>\n",
       "      <td>7</td>\n",
       "      <td>2.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  freq_qid1  freq_qid2  q1len  q2len  q1_n_words  q2_n_words  \\\n",
       "0   0          1          1     66     57          14          12   \n",
       "1   1          1          1     51     88           8          13   \n",
       "2   2          1          1     73     59          14          10   \n",
       "3   3          1          1     50     65          11           9   \n",
       "4   4          1          1     76     39          13           7   \n",
       "\n",
       "   word_Common  word_Total  word_share  freq_q1+q2  freq_q1-q2  \n",
       "0         10.0        23.0    0.434783           2           0  \n",
       "1          4.0        20.0    0.200000           2           0  \n",
       "2          4.0        24.0    0.166667           2           0  \n",
       "3          0.0        19.0    0.000000           2           0  \n",
       "4          2.0        20.0    0.100000           2           0  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# data before preprocessing \n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_1YIPtTwdMWC",
    "outputId": "510f4c73-0706-4633-d706-e0d348ebfa71"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>86</th>\n",
       "      <th>87</th>\n",
       "      <th>88</th>\n",
       "      <th>89</th>\n",
       "      <th>90</th>\n",
       "      <th>91</th>\n",
       "      <th>92</th>\n",
       "      <th>93</th>\n",
       "      <th>94</th>\n",
       "      <th>95</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>211.327493</td>\n",
       "      <td>-144.777963</td>\n",
       "      <td>-68.724038</td>\n",
       "      <td>-154.424293</td>\n",
       "      <td>-90.765352</td>\n",
       "      <td>2.541932</td>\n",
       "      <td>136.953358</td>\n",
       "      <td>50.734912</td>\n",
       "      <td>-63.741751</td>\n",
       "      <td>57.345160</td>\n",
       "      <td>...</td>\n",
       "      <td>33.424773</td>\n",
       "      <td>-102.977361</td>\n",
       "      <td>144.956313</td>\n",
       "      <td>50.869276</td>\n",
       "      <td>-21.612809</td>\n",
       "      <td>35.889588</td>\n",
       "      <td>-71.494379</td>\n",
       "      <td>4.160346</td>\n",
       "      <td>-131.862783</td>\n",
       "      <td>72.127579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>142.841313</td>\n",
       "      <td>-114.033673</td>\n",
       "      <td>-110.215671</td>\n",
       "      <td>-103.034122</td>\n",
       "      <td>-87.741411</td>\n",
       "      <td>15.190485</td>\n",
       "      <td>55.168690</td>\n",
       "      <td>100.432233</td>\n",
       "      <td>7.681387</td>\n",
       "      <td>178.259341</td>\n",
       "      <td>...</td>\n",
       "      <td>67.073067</td>\n",
       "      <td>20.522029</td>\n",
       "      <td>41.012347</td>\n",
       "      <td>-0.266897</td>\n",
       "      <td>95.695290</td>\n",
       "      <td>-36.636391</td>\n",
       "      <td>-121.102605</td>\n",
       "      <td>70.353590</td>\n",
       "      <td>-17.043896</td>\n",
       "      <td>-7.070883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>82.560924</td>\n",
       "      <td>-142.533623</td>\n",
       "      <td>0.726614</td>\n",
       "      <td>-104.875443</td>\n",
       "      <td>-84.751818</td>\n",
       "      <td>22.521084</td>\n",
       "      <td>115.942030</td>\n",
       "      <td>50.422234</td>\n",
       "      <td>-112.165931</td>\n",
       "      <td>52.261222</td>\n",
       "      <td>...</td>\n",
       "      <td>61.786713</td>\n",
       "      <td>-50.324955</td>\n",
       "      <td>107.575190</td>\n",
       "      <td>-11.787163</td>\n",
       "      <td>-40.993720</td>\n",
       "      <td>-27.191091</td>\n",
       "      <td>-12.928715</td>\n",
       "      <td>1.654342</td>\n",
       "      <td>-100.863351</td>\n",
       "      <td>148.836797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-125.975133</td>\n",
       "      <td>-59.422360</td>\n",
       "      <td>-67.570983</td>\n",
       "      <td>-137.758572</td>\n",
       "      <td>-100.720235</td>\n",
       "      <td>87.775736</td>\n",
       "      <td>-23.037602</td>\n",
       "      <td>85.907325</td>\n",
       "      <td>27.632180</td>\n",
       "      <td>50.557094</td>\n",
       "      <td>...</td>\n",
       "      <td>117.428018</td>\n",
       "      <td>-13.144253</td>\n",
       "      <td>-1.376010</td>\n",
       "      <td>77.991531</td>\n",
       "      <td>23.797347</td>\n",
       "      <td>12.770571</td>\n",
       "      <td>-8.103193</td>\n",
       "      <td>122.957298</td>\n",
       "      <td>63.929072</td>\n",
       "      <td>-24.856102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>299.594228</td>\n",
       "      <td>-188.401305</td>\n",
       "      <td>-21.267282</td>\n",
       "      <td>-271.166976</td>\n",
       "      <td>-186.462065</td>\n",
       "      <td>105.778991</td>\n",
       "      <td>170.331633</td>\n",
       "      <td>-69.645959</td>\n",
       "      <td>-96.292431</td>\n",
       "      <td>134.757989</td>\n",
       "      <td>...</td>\n",
       "      <td>61.035960</td>\n",
       "      <td>-172.486168</td>\n",
       "      <td>246.922066</td>\n",
       "      <td>29.651128</td>\n",
       "      <td>-27.454099</td>\n",
       "      <td>-27.704648</td>\n",
       "      <td>-62.081455</td>\n",
       "      <td>3.472992</td>\n",
       "      <td>-119.313633</td>\n",
       "      <td>108.889052</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 96 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0           1           2           3           4           5   \\\n",
       "0  211.327493 -144.777963  -68.724038 -154.424293  -90.765352    2.541932   \n",
       "1  142.841313 -114.033673 -110.215671 -103.034122  -87.741411   15.190485   \n",
       "2   82.560924 -142.533623    0.726614 -104.875443  -84.751818   22.521084   \n",
       "3 -125.975133  -59.422360  -67.570983 -137.758572 -100.720235   87.775736   \n",
       "4  299.594228 -188.401305  -21.267282 -271.166976 -186.462065  105.778991   \n",
       "\n",
       "           6           7           8           9      ...              86  \\\n",
       "0  136.953358   50.734912  -63.741751   57.345160     ...       33.424773   \n",
       "1   55.168690  100.432233    7.681387  178.259341     ...       67.073067   \n",
       "2  115.942030   50.422234 -112.165931   52.261222     ...       61.786713   \n",
       "3  -23.037602   85.907325   27.632180   50.557094     ...      117.428018   \n",
       "4  170.331633  -69.645959  -96.292431  134.757989     ...       61.035960   \n",
       "\n",
       "           87          88         89         90         91          92  \\\n",
       "0 -102.977361  144.956313  50.869276 -21.612809  35.889588  -71.494379   \n",
       "1   20.522029   41.012347  -0.266897  95.695290 -36.636391 -121.102605   \n",
       "2  -50.324955  107.575190 -11.787163 -40.993720 -27.191091  -12.928715   \n",
       "3  -13.144253   -1.376010  77.991531  23.797347  12.770571   -8.103193   \n",
       "4 -172.486168  246.922066  29.651128 -27.454099 -27.704648  -62.081455   \n",
       "\n",
       "           93          94          95  \n",
       "0    4.160346 -131.862783   72.127579  \n",
       "1   70.353590  -17.043896   -7.070883  \n",
       "2    1.654342 -100.863351  148.836797  \n",
       "3  122.957298   63.929072  -24.856102  \n",
       "4    3.472992 -119.313633  108.889052  \n",
       "\n",
       "[5 rows x 96 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Questions 1 tfidf weighted word2vec\n",
    "df3_q1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wUMdkJTNdMWL",
    "outputId": "69e3e256-cbb8-4fe2-aaf2-9088c3868b29"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>86</th>\n",
       "      <th>87</th>\n",
       "      <th>88</th>\n",
       "      <th>89</th>\n",
       "      <th>90</th>\n",
       "      <th>91</th>\n",
       "      <th>92</th>\n",
       "      <th>93</th>\n",
       "      <th>94</th>\n",
       "      <th>95</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>152.150878</td>\n",
       "      <td>-127.275134</td>\n",
       "      <td>-31.749491</td>\n",
       "      <td>-143.763975</td>\n",
       "      <td>-98.000371</td>\n",
       "      <td>9.522685</td>\n",
       "      <td>107.033391</td>\n",
       "      <td>37.073909</td>\n",
       "      <td>-36.444822</td>\n",
       "      <td>54.110217</td>\n",
       "      <td>...</td>\n",
       "      <td>29.179625</td>\n",
       "      <td>-108.492959</td>\n",
       "      <td>131.753666</td>\n",
       "      <td>42.551238</td>\n",
       "      <td>-15.014939</td>\n",
       "      <td>15.559760</td>\n",
       "      <td>-59.914421</td>\n",
       "      <td>-9.710103</td>\n",
       "      <td>-100.494285</td>\n",
       "      <td>58.079703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>148.997841</td>\n",
       "      <td>-44.465574</td>\n",
       "      <td>-101.379184</td>\n",
       "      <td>-125.883334</td>\n",
       "      <td>-116.109336</td>\n",
       "      <td>44.848494</td>\n",
       "      <td>134.104035</td>\n",
       "      <td>26.338358</td>\n",
       "      <td>-77.135588</td>\n",
       "      <td>83.961670</td>\n",
       "      <td>...</td>\n",
       "      <td>118.257488</td>\n",
       "      <td>4.803217</td>\n",
       "      <td>56.622080</td>\n",
       "      <td>91.515271</td>\n",
       "      <td>138.080721</td>\n",
       "      <td>-30.453486</td>\n",
       "      <td>-21.980228</td>\n",
       "      <td>86.011098</td>\n",
       "      <td>-25.022780</td>\n",
       "      <td>11.250763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6.616661</td>\n",
       "      <td>-29.885251</td>\n",
       "      <td>-119.091992</td>\n",
       "      <td>-99.385166</td>\n",
       "      <td>-19.594293</td>\n",
       "      <td>-9.981105</td>\n",
       "      <td>142.606486</td>\n",
       "      <td>91.884172</td>\n",
       "      <td>51.449668</td>\n",
       "      <td>13.693213</td>\n",
       "      <td>...</td>\n",
       "      <td>129.177678</td>\n",
       "      <td>18.698502</td>\n",
       "      <td>59.104817</td>\n",
       "      <td>88.825091</td>\n",
       "      <td>-86.036293</td>\n",
       "      <td>72.855847</td>\n",
       "      <td>-11.356267</td>\n",
       "      <td>-60.352530</td>\n",
       "      <td>-100.171914</td>\n",
       "      <td>96.118610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-6.760001</td>\n",
       "      <td>-44.608786</td>\n",
       "      <td>-17.806797</td>\n",
       "      <td>-61.250319</td>\n",
       "      <td>-7.154842</td>\n",
       "      <td>16.542798</td>\n",
       "      <td>96.313375</td>\n",
       "      <td>-2.358248</td>\n",
       "      <td>-12.391162</td>\n",
       "      <td>-27.797972</td>\n",
       "      <td>...</td>\n",
       "      <td>70.816154</td>\n",
       "      <td>-30.719308</td>\n",
       "      <td>85.571856</td>\n",
       "      <td>50.214468</td>\n",
       "      <td>25.514955</td>\n",
       "      <td>-27.231886</td>\n",
       "      <td>22.942071</td>\n",
       "      <td>-4.807315</td>\n",
       "      <td>-46.899339</td>\n",
       "      <td>57.239975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>95.189887</td>\n",
       "      <td>-70.992464</td>\n",
       "      <td>21.328272</td>\n",
       "      <td>-92.314399</td>\n",
       "      <td>-106.132173</td>\n",
       "      <td>10.319852</td>\n",
       "      <td>91.417332</td>\n",
       "      <td>-40.342474</td>\n",
       "      <td>-34.476539</td>\n",
       "      <td>55.976651</td>\n",
       "      <td>...</td>\n",
       "      <td>19.032317</td>\n",
       "      <td>-70.004583</td>\n",
       "      <td>87.144190</td>\n",
       "      <td>38.693220</td>\n",
       "      <td>-13.824600</td>\n",
       "      <td>-12.965596</td>\n",
       "      <td>47.150454</td>\n",
       "      <td>-24.741699</td>\n",
       "      <td>-52.968391</td>\n",
       "      <td>-2.464822</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 96 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0           1           2           3           4          5   \\\n",
       "0  152.150878 -127.275134  -31.749491 -143.763975  -98.000371   9.522685   \n",
       "1  148.997841  -44.465574 -101.379184 -125.883334 -116.109336  44.848494   \n",
       "2    6.616661  -29.885251 -119.091992  -99.385166  -19.594293  -9.981105   \n",
       "3   -6.760001  -44.608786  -17.806797  -61.250319   -7.154842  16.542798   \n",
       "4   95.189887  -70.992464   21.328272  -92.314399 -106.132173  10.319852   \n",
       "\n",
       "           6          7          8          9     ...              86  \\\n",
       "0  107.033391  37.073909 -36.444822  54.110217    ...       29.179625   \n",
       "1  134.104035  26.338358 -77.135588  83.961670    ...      118.257488   \n",
       "2  142.606486  91.884172  51.449668  13.693213    ...      129.177678   \n",
       "3   96.313375  -2.358248 -12.391162 -27.797972    ...       70.816154   \n",
       "4   91.417332 -40.342474 -34.476539  55.976651    ...       19.032317   \n",
       "\n",
       "           87          88         89          90         91         92  \\\n",
       "0 -108.492959  131.753666  42.551238  -15.014939  15.559760 -59.914421   \n",
       "1    4.803217   56.622080  91.515271  138.080721 -30.453486 -21.980228   \n",
       "2   18.698502   59.104817  88.825091  -86.036293  72.855847 -11.356267   \n",
       "3  -30.719308   85.571856  50.214468   25.514955 -27.231886  22.942071   \n",
       "4  -70.004583   87.144190  38.693220  -13.824600 -12.965596  47.150454   \n",
       "\n",
       "          93          94         95  \n",
       "0  -9.710103 -100.494285  58.079703  \n",
       "1  86.011098  -25.022780  11.250763  \n",
       "2 -60.352530 -100.171914  96.118610  \n",
       "3  -4.807315  -46.899339  57.239975  \n",
       "4 -24.741699  -52.968391  -2.464822  \n",
       "\n",
       "[5 rows x 96 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Questions 2 tfidf weighted word2vec\n",
    "df3_q2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ozz83vh4dMWU",
    "outputId": "e5b30f77-2849-4b08-9949-0912ec0db418"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features in nlp dataframe : 17\n",
      "Number of features in preprocessed dataframe : 12\n",
      "Number of features in question1 w2v  dataframe : 96\n",
      "Number of features in question2 w2v  dataframe : 96\n",
      "Number of features in final dataframe  : 221\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of features in nlp dataframe :\", df1.shape[1])\n",
    "print(\"Number of features in preprocessed dataframe :\", df2.shape[1])\n",
    "print(\"Number of features in question1 w2v  dataframe :\", df3_q1.shape[1])\n",
    "print(\"Number of features in question2 w2v  dataframe :\", df3_q2.shape[1])\n",
    "print(\"Number of features in final dataframe  :\", df1.shape[1]+df2.shape[1]+df3_q1.shape[1]+df3_q2.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HmfZ5Q1zdMWl"
   },
   "outputs": [],
   "source": [
    "# storing the final features to csv file\n",
    "if not os.path.isfile('final_features.csv'):\n",
    "    df3_q1['id']=df1['id']\n",
    "    df3_q2['id']=df1['id']\n",
    "    df1  = df1.merge(df2, on='id',how='left')\n",
    "    df2  = df3_q1.merge(df3_q2, on='id',how='left')\n",
    "    result  = df1.merge(df2, on='id',how='left')\n",
    "    result.to_csv('final_features.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data = pd.read_csv('final_features.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100000, 221)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "3.Q_Mean_W2V.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
